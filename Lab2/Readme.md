Here is your **properly formatted, clean, copy-paste ready README.md** file:

---

# ğŸ· Vinous-ML: Automated Wine Quality Analytics

## End-to-End ML Orchestration with Apache Airflow & Docker

Vinous-ML is an automated Machine Learning pipeline that classifies wine quality based on chemical properties. Using the **WineQT dataset**, this project demonstrates full ML lifecycle orchestration using **Apache Airflow**, **Docker**, and **Scikit-learn** â€” from ingestion to evaluation.

---

## ğŸ¯ Project Objective

The goal is to move beyond regression and implement a robust **Binary Classification** model.

### ğŸ”„ Target Transformation

Original quality scores (1â€“10) are converted into binary labels:

* **Good (1)** â†’ Quality â‰¥ 7
* **Bad (0)** â†’ Quality < 7

### ğŸ¤– Model Strategy

* **Algorithm:** Decision Tree Classifier
* **Optimization:** `GridSearchCV` for hyperparameter tuning
* **Handling Imbalance:** Stratified splitting + depth regularization

This ensures better generalization and avoids overfitting on imbalanced wine quality distributions.

---

## ğŸ“‚ Project Structure

Ensure your project directory is structured exactly as shown below for proper Docker volume mapping:

```
Lab-2/
â”‚   â”œâ”€â”€ winedag.py               # DAG Definition (Orchestrator)
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ WineQT.csv           # Raw Dataset
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â””â”€â”€ wine_dt_model.sav    # Optimized Pickle File
â”‚   â””â”€â”€ src/
â”‚       â””â”€â”€ lab.py               # ML Logic (Preprocessing & Training)
â”œâ”€â”€ .env                         # User UID/GID Configuration
â””â”€â”€ docker-compose.yaml          # Multi-container Setup
```

---

## ğŸ›  Setup & Installation

### 1ï¸âƒ£ Environment Preparation

Initialize required folders and configure Airflow UID to prevent permission conflicts:

```bash
mkdir -p ./dags/data ./dags/model ./dags/src ./logs ./plugins
echo -e "AIRFLOW_UID=$(id -u)" > .env
```

---

### 2ï¸âƒ£ Dependency Configuration

Update your `docker-compose.yaml` file to include required scientific libraries:

```yaml
_PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:- pandas scikit-learn numpy}
```

---

### 3ï¸âƒ£ Launching the Airflow Cluster

Initialize Airflow metadata:

docker compose up airflow-init


Start all services:

docker compose up -d

Access the Airflow UI:

http://localhost:8080

**Default credentials:**

* Username: `airflow2`
* Password: `airflow2`

---

## ğŸ”„ Pipeline Workflow

The DAG defined in `winedag.py` executes the following tasks in strict sequence:

### 1ï¸âƒ£ Setup â€” `setup_directories`

Ensures the model export directory exists on the host machine.

### 2ï¸âƒ£ Ingestion â€” `load_data_task`

* Loads the WineQT dataset
* Performs initial cleaning

### 3ï¸âƒ£ ETL â€” `preprocess_data_task`

* Applies binary labeling
* Performs stratified train/test split
* Applies `StandardScaler` feature normalization

### 4ï¸âƒ£ Optimization â€” `train_save_model_task`

* Executes `GridSearchCV`
* Tunes `max_depth` to prevent overfitting
* Saves the best model as a `.sav` file

### 5ï¸âƒ£ Evaluation â€” `evaluate_model_task`

* Reloads optimized model
* Generates:

  * Confusion Matrix
  * ROC-AUC Score
  * ASCII-rendered Feature Importance chart

---

## ğŸ“Š How to Analyze Results

After DAG execution (all tasks turn **dark green**):

1. Click on **`evaluate_model_task`**
2. Open the **Logs** tab
3. Review:

   * Model accuracy metrics
   * ROC-AUC score
   * Feature Importance ranking (Alcohol, Volatile Acidity, etc.)

This allows performance auditing directly inside Airflow logs.

---

## ğŸ§¹ Cleanup

To stop and remove all containers:

docker compose down

---

## ğŸš€ Tech Stack

* Apache Airflow
* Docker & Docker Compose
* Python 3
* Scikit-learn
* Pandas
* NumPy


